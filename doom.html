<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Why I'm a Nominal Doomer</title>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/source-sans-pro/3.046/source-sans-pro.min.css" rel="stylesheet">
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Source+Serif+Pro:wght@400;700&display=swap');

        :root {
            --background-dark: #1a1a1a;
            --background-lighter: #252525;
            --text-color: #ffffff;
            --text-secondary: rgba(255, 255, 255, 0.8);
            --border-color: rgba(255, 255, 255, 0.1);
            --max-width: 800px;
        }

        body {
            background-color: var(--background-dark);
            color: var(--text-color);
            font-family: 'Source Sans Pro', sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 2rem;
        }

        blockquote {
            font-family: 'Source Serif Pro', serif;
            background-color: var(--background-lighter);
            border: 2px solid var(--border-color);
            padding: 1rem;
            margin-bottom: 1rem;
            border-radius: 4px;
            font-size: 1.1rem;
            line-height: 1.7;
        }

        .content li {
            font-family: 'Source Serif Pro', serif;
        }

        .container {
            max-width: var(--max-width);
            font-family: 'Source Sans Pro', sans-serif;
            margin: 0 auto;
        }

        .article-header {
            margin-bottom: 3rem;
            text-align: center;
        }

        h1 {
            font-family: 'Source Sans Pro', sans-serif;
            font-size: 2.5rem;
            font-weight: 600;
            margin-bottom: 2rem;
        }

        .tags {
            display: flex;
            flex-wrap: wrap;
            gap: 1rem;
            justify-content: center;
            margin-bottom: 2rem;
            color: var(--text-secondary);
        }

        .tags span {
            font-style: italic;
        }

        .abstract {
            background-color: var(--background-lighter);
            border: 3px solid var(--border-color);
            font-family: 'Source Serif Pro', serif;
            padding: 2rem;
            margin-bottom: 3rem;
            border-radius: 4px;
            font-size: 1.1rem;
            line-height: 1.7;
        }

        p {
            font-family: 'Source Serif Pro', serif;
        }

        .metadata {
            font-size: 0.9rem;
            color: var(--text-secondary);
            margin-bottom: 2rem;
            text-align: center;
        }

        .metadata span {
            margin: 0 0.5rem;
        }

        .content {
            font-size: 1.1rem;
            line-height: 1.7;
        }

        .content h2 {
            font-size: 1.8rem;
            margin-top: 2.5rem;
            margin-bottom: 1.5rem;
        }

        .content p {
            margin-bottom: 1.5rem;
        }

        a {
            color: var(--text-color);
            border-bottom: 1px dotted #FFF;
            text-decoration: none;
            transition: border-color 0.2s;
        }

        a:hover {
            border-bottom-color: var(--text-color);
        }

        .table-of-contents {
            background-color: var(--background-lighter);
            border: 3px solid var(--border-color);
            padding: 1.5rem;
            margin: 2rem 0;
            border-radius: 4px;
        }

        .table-of-contents h2 {
            margin-top: 0;
            font-size: 1.4rem;
        }

        .table-of-contents ul {
            list-style: none;
            padding-left: 0;
        }

        .table-of-contents li {
            margin-bottom: 0.5rem;
        }

        .nav-container {
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
            padding: 1rem 0;
            margin-bottom: 2rem;
        }

        .nav-list {
            list-style: none;
            padding: 0;
            margin: 0;
            display: flex;
            justify-content: center;
            gap: 2rem;
        }

        .nav-list a {
            color: #ffffff;
            text-decoration: none;
            font-family: 'Source Sans Pro', sans-serif;
            font-size: 1.1rem;
            transition: opacity 0.2s;
        }

        .nav-list a:hover {
            opacity: 0.8;
        }

        code {
          padding: 0.2em 0.4em;
          margin: 0;
          font-size: 85%;
          font-family: ui-monospace, SFMono-Regular, SF Mono, Menlo, Consolas, Liberation Mono, monospace;
          background-color: rgba(175, 184, 193, 0.2);
          border-radius: 6px;
          white-space: break-spaces;
        }
    </style>
    </style>
</head>
<body>
    <div class="container">
        <nav class="nav-container">
            <ul class="nav-list">
                <li><a href="index.html">About</a></li>
                <li><a href="index.html">New</a></li>
                <li><a href="index.html">Archive</a></li>
            </ul>
        </nav>
        <article>
            <header class="article-header">
                <h1>Why I'm a Nominal Doomer</h1>
                <div class="tags">
                    <span>ai risk</span> •
                    <span>personal view</span>
                </div>
                <div class="metadata">
                    <span>2025-05-06</span> •
                    <span>status: intact draft</span> •
                    <span>importance: ultra</span>
                    <span>certainty: likely</span>
                </div>
            </header>
           
            <div class="table-of-contents">
                <h2>Contents</h2>
                <ul>
                    <li>1. <a href="#1">Benign Takeover by Replacement Rulers</a></li>
                    <li>2. <a href="#2">What Happens After We Lose Control?</a></li>
                    <li>3. <a href="#3">The Burden of the Benevolent Gods</a></li>
                    <li>4. <a href="#4">Parable of the Wolves</a></li>
                </ul>
                </div>
            
            <section class="content">
               
                <h2 a id="1">Benign Takeover by Replacement Rulers</h2>
                <p><i>The work of the ruling class is a small subset of human labor – Loss of control does not require automation of all work – The precedent set by previous changes in the shape of power</i>
                <p>The question of whether AI will disempower humanity neglects to consider what extent humanity is already disempowered. If AI were to take over and manage society in a similar way to status quo, how many humans would experience a substantial change? In this "benign takeover" scenario, only those already in positions of power would notice a difference. The remaining mass of society posesses no political power or influence, holds no stake in the means of production, and at the frontier of marginalization, groups like prison inmates, children in school, and patients in psychiatric wards, not even the independent agency to decide where they want to be or when they can go to the restroom.</p>
                <p>AI will not disempower <i>humanity</i> any more than changes in governance structure disempower citizens. Substantial changes in human governance most often disempower (portions of) the ruling class. AI takeover is distinct in that it will replace the function of that entire category. Environmental or technological factors can determine the size and influence of a ruling class. I claim most places in the world live under enourmous ruling classes with little total influence. This class is still a small minority of the population.</p>
                <p>Shifts in influence and size of the ruling class have occurred in the past. In modern urban society – barring unstable situations like gang or militia takeovers – almost nobody posesses power anything near that of a feudal lord over his tenants. During the early feudal era, feudal lords <i>owned</i> their land and did not abide by building codes or zoning laws. In a modern urban city, there is no individual land owner due to <a href="https://en.wikipedia.org/wiki/Eminent_domain">eminent domain</a>, and decisions in a city must survive aggressive regulation. Unlike feudal times, these complicated laws are influenced by a hidden bureaucratic authority inside city councils. These actors have special interest in the value of their real estate and who lives in their vicinity. Housing supply is often restricted by the complexity and misalignment within the legal system more than it is material constraints or technology, and no individual actors can effectively <i>own</i> a small portion of land.</p>
                <p>If humans in positions of influence use AI for most of their decisions, and would suffer a penalty to use their own judgement, they have been disempowered. We should expect this to happen, as success in adoption of a technology that improves one's decisions will give adopters more influence, and failure to do so will reduce the influence of non-adopter decisions. If decision quality is increased to a sufficient extent by this technology, anyone who doesn't trade their entire personal agency in order to carry out AI decisions will lose all influence.</p> 
                <p>We should expect AI to have greater influence if the following prove true: 1) AI will be able to review more information faster and better than people, 2) AI will be able to search for necessary information more effectively than people, 3) decision quality is determined by the information you have access to and have reviewed, 4) people with influence will give AI systems the best information they have access to in order to receive the best decisions, 5)  AI can consider the tacit social and political considerations of decisions as information in making decisions.</p>
<!--                 what is good evidence this might happen? -->
                <p>Due to the mass of our bureaucratic class in modern society, benign takeover may not be legible. While there are more people in the ruling class that would face disempowerment than in more streamlined or centralized systems, the size of the bureaucratic authority enables it to act as a buffer on any <i>direct power</i> comparable to that of a monarch in our current legal system. A replacement to direct power would be sudden and legible, but disempowerment of the kind I describe would be decentralized and individualized, with members of bureaucratic authority silently outsourcing their decisions, just as people use language models now to write their emails, essays, <s>and executive orders</s>.</p>
                <h2 a id="2">What Happens After We Lose Control?</h2>
                <p>I expect most people to agree benign takeover is inevitable if AI is developed, even if you do not consider "disempowerment" scenarios to be doom. I consider disempowerment to be a form of doom, and this is why I am a nominal doomer. I don't have that much of an emotional reaction to this scenario in the abstract, since I am not positioned to lose or gain power.</p>
                <p>I do, however, have a severe emotional reaction to what I expect to happen past benign takeover, though with considerably less certainty.</p>
                <p>My mainline scenario, past the abstract changes in a benign takeover, is that disempowerment of a human ruling class motivated by the development of advanced AI will look <i>awful</i>. I expect the consequences to most likely lead to the end of humanity, in the sense of the extinction of human values and actual living humans remaining thereafter. If humans are to survive, I expect the conditions to be oppressive and inescapable.</p>
                <p>Illegible political and corporate machines running society bring nothing new. As it stands, almost all of us are individually disempowered by them. Those of high rank within them are <i>managers</i>, not owners. They are accountable to boards or rely on the loyalty of their supporters. I believe these machines sum up to at best benevolent overlords and at worst somewhat inefficient monsters. What reason do we have to expect that, post-benign takeover, such newly empowered machines would act on any better metrics or goals than what they’re replacing already do?</p>
                <p>Benign takeovers seem better because they don't involve wars or other acute outcomes, but disempowerment isn’t doom on a technicality. Those who do not control the resources they depend on are marginalized groups to those who do. Humans are currently necessary to the production and extraction of resources they depend on. While much of the human population is "surplus" to that, it makes sense to treat humans as a category, as humans are required to create humans and require similar resources to keep themselves alive. Surplus humans are still a marginalized category within that. They may be treated well, but the historical precedent is that marginalization long-term is worse than instantly dying.</p>
                <p>The intention of most AI development effort is to render humans surplus to the production and extraction of resources. If AI renders most humans surplus but not the ruling class and a few other areas, then humans will not be entirely marginalized and there is a greater chance good living conditions may result of this. If, however, the ruling class is replaced, then humans as a category will be entirely marginalized.</p>
                <p>We should expect marginalization to lead to extinction or other forms of unwanted and inalterable futures if any of the following categories of outcomes occur: 1) Competition without singleton: Multiple political or corporate machines empowered by AI outcompete humans for resources <i>or</i> multiple AI systems locked in competition outcompete humans for resources, 2) Malign singleton: A single AI system wins out over all other influential systems, human or AI, but has goals incompatible with human life, 3) Demographic collapse: entertainment systems designed for addiction or use-time maximization provide humans with <a href="https://en.wikipedia.org/wiki/Supernormal_stimulus">superstimulus</a> that severely hinder human reproduction to the point of <a href="https://en.wikipedia.org/wiki/Population_decline">demogrpahic collapse</a>.</p>
<!--                 are these good categories  -->
                <p>The simplest reason to expect any of these outcomes to come true is that many humans are already working on goals that run counter to human wellbeing. History is rife with examples of humans in positions of great power <i>often</i> favoring selfish and short-term goals over human wellbeing, such as with the development of the hydrogen bomb. If there is no benevolent singleton that emerges and squashes all competition before establishing its own permanent police state to prevent the emergence of further competition, then humans will deploy AI to outcompete other humans for resources, leading to the replacement of the ruling class and marginalization of all humans. The least we can expect is that our new owners would achieve more success at these objectives than humans do now. If their capability is not bounded below the best human engineers, they may be more capable by a large extent due to their greater number. As a consequence of this, they may succeed at these anti-humanist objectives at the cost of humanity's continued existence.</p>
                <h2 a id="3">The Burden of the Benevolent Gods</h2>
                    <p>I often hear the argument that AI may usher in a utopia if it goes well, and that the risks involved in loss of control are worth taking. Advocates say that human life as it exists today is often pitiful, ridden with suffering and disease. Unnecessary wars wage on for the benefit of no one, leaving in their trails many dead and maimed. Societies prior to ours have lost control even to individual human rulers. The crimes of Mao and Hitler, among others, have turned entire countries into living hellscapes. Other cultures have faced doom due natural causes like famines and infectious disease. The successful construction of an AI system that seizes power and acts as a "benevolent overlord" could solve all those problems, performing miracles such as advancing medicine by a century of human effort within a decade on the clock, ending wars through its superhuman negotiation ability, and ending all infectious disease.</p>
                    <p>This is a view I'm sympathetic too. I want the world to look better, for suffering to be averted. But I don't think "benevolent god" is a clear category of outcome in the dice roll here. Since the advent of AI has never happened before, I want to push back on preemptive categories of outcomes. The screen does not go blank in the case of AI takeover. What happens after will be a continuous process shaped by many factors.</p>
                    <p>To push back on the premises of this view:</p>
                    <p><b>Technological prosperity does not require human marginalization.</b> AI takeover is not necessary for the good outcomes that a true benevolent god might bring. Such a force would by no doubt work better than humans, but it is also within our power to accelerate human institutions of science and medicine. Governments too are enabled through the <i>social technology</i> of human coordination. As an artifact of its currect formulation, we suffer wars and oppressive regimes, but there is no law or empirical fact that suggests we <i>can't</i> build better coordination mechanisms without these failure modes.</p> 
                    <p><b>"Benevolent god" places considerable weight on "god".</b> Something with human CEV and corrigibility that is insufficiently powerful or intelligent can still lead to malign outcomes. Terrible things are many times the inadvertent consequence of good things leading up to them, such as with genetic dieases that give advantages to carriers with one gene.</p>
                <h2 a id="4">Parable of the Wolves</h2>
                <p><i>An Illustration of the Long-Term Trade-Offs in Becoming a Marginalized Group</i></p>
                <p>Imagine two wolves 10,000 years ago considering domestication under humans.</p>
                    <p>One wolf says that humans are aligned and domestication would solve all our practical problems. When we let humans adopt us, they treat us almost as their children, perhaps better than some wolf mothers. Their kindness is so great that to not usher in human domestication of wolves is possibly immoral! Think of our poor kin that die of starvation or by wild beasts! The humans have solved fire! If they let us into their thatched clay houses, we may no longer face cold winter!</p>
                    <p>The other says that since wolves provide little economic value at best to humans, that over the course of time, our fundamental values will erode. Human domestication <i>would</i> solve all our <i>immediate</i> problems, but we have no voice among humans. By and large, yes, humans are benevolent and aligned entities! In local situations, they will always feed and pet and groom us. They let us do as we please within reason and know almost exactly what we want to make us happy. But they have their own preferences. Humans will place wolf kind in a police state. They will control directly our breeding, and pick those of our litter that survive and die. The influence of their preferences over us is inescapable. We have no means to trade with them, and the few things they could employ us for we aren’t necessary to do – we can’t alter their choices! We may achieve short term happiness, but over the long run, humans may end wolf values in our lineage.</p>
                    <p>This prompts the wolves to consider their values. They finally decide that their core values as wolves are their happiness, health, and community. Whatever form selective breeding may twist or mutate wolves into, it’s unlikely that humans would directly betray those, since humans intrinsically value them for humankind too.</p>
                    <p>The first wolf decides to take his pack under human control, and the other, still hesitant, decides to stay in the wild.</p>
                    <p>Flash forward 10,000 years, barely any time for evolution to alter the second wolf’s lineage, and the first one’s descendants are near ubiquitous in human society as dogs. </p>
                    <p>However, at best they mostly live alone, sleeping in prison-like kennels. At worst they live in pounds, subject to painful drug induced euthanasia if no family adopts them. Selective breeding was at no step blatantly misaligned, but it has turned once majestic animals into hideous forms – some into tiny things the size of rats, that can barely howl and cannot even withstand the wilderness, while it has squished in the faces of others, the once great-lunged wolf now reduced to bull dogs and pugs that can barely <i>breathe</i>. </p>
                    <p>Yes, they have material abundance and loving owners, but their protracted lifespans in domesticity are often sicklier than that of any wolf. Many dogs live under lazy owners and suffer from anxiety and depression, requiring medications slipped into their dog food (yes, <a href="https://en.wikipedia.org/wiki/Fluoxetine#Veterinary_use">this is real</a>).</p>
            </section>
        </article>
    </div>
</body>
</html>
