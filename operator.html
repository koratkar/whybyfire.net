<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>I Am the Antichrist to You is about Nuclear War</title>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/source-sans-pro/3.046/source-sans-pro.min.css" rel="stylesheet">
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Source+Serif+Pro:wght@400;700&display=swap');

        :root {
            --background-dark: #1a1a1a;
            --background-lighter: #252525;
            --text-color: #ffffff;
            --text-secondary: rgba(255, 255, 255, 0.8);
            --border-color: rgba(255, 255, 255, 0.1);
            --max-width: 800px;
        }

        body {
            background-color: var(--background-dark);
            color: var(--text-color);
            font-family: 'Source Sans Pro', sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 2rem;
        }

        blockquote {
            font-family: 'Source Serif Pro', serif;
            background-color: var(--background-lighter);
            border: 2px solid var(--border-color);
            padding: 1rem;
            margin-bottom: 1rem;
            border-radius: 4px;
            font-size: 1.1rem;
            line-height: 1.7;
        }

        .content li {
            font-family: 'Source Serif Pro', serif;
        }

        .container {
            max-width: var(--max-width);
            font-family: 'Source Sans Pro', sans-serif;
            margin: 0 auto;
        }

        .article-header {
            margin-bottom: 3rem;
            text-align: center;
        }

        h1 {
            font-family: 'Source Sans Pro', sans-serif;
            font-size: 2.5rem;
            font-weight: 600;
            margin-bottom: 2rem;
        }

        .tags {
            display: flex;
            flex-wrap: wrap;
            gap: 1rem;
            justify-content: center;
            margin-bottom: 2rem;
            color: var(--text-secondary);
        }

        .tags span {
            font-style: italic;
        }

        .abstract {
            background-color: var(--background-lighter);
            border: 3px solid var(--border-color);
            font-family: 'Source Serif Pro', serif;
            padding: 2rem;
            margin-bottom: 3rem;
            border-radius: 4px;
            font-size: 1.1rem;
            line-height: 1.7;
        }

        p {
            font-family: 'Source Serif Pro', serif;
        }

        .metadata {
            font-size: 0.9rem;
            color: var(--text-secondary);
            margin-bottom: 2rem;
            text-align: center;
        }

        .metadata span {
            margin: 0 0.5rem;
        }

        .content {
            font-size: 1.1rem;
            line-height: 1.7;
        }

        .content h2 {
            font-size: 1.8rem;
            margin-top: 2.5rem;
            margin-bottom: 1.5rem;
        }

        .content p {
            margin-bottom: 1.5rem;
        }

        a {
            color: var(--text-color);
            border-bottom: 1px dotted #FFF;
            text-decoration: none;
            transition: border-color 0.2s;
        }

        a:hover {
            border-bottom-color: var(--text-color);
        }

        .table-of-contents {
            background-color: var(--background-lighter);
            border: 3px solid var(--border-color);
            padding: 1.5rem;
            margin: 2rem 0;
            border-radius: 4px;
        }

        .table-of-contents h2 {
            margin-top: 0;
            font-size: 1.4rem;
        }

        .table-of-contents ul {
            list-style: none;
            padding-left: 0;
        }

        .table-of-contents li {
            margin-bottom: 0.5rem;
        }

        .nav-container {
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
            padding: 1rem 0;
            margin-bottom: 2rem;
        }

        .nav-list {
            list-style: none;
            padding: 0;
            margin: 0;
            display: flex;
            justify-content: center;
            gap: 2rem;
        }

        .nav-list a {
            color: #ffffff;
            text-decoration: none;
            font-family: 'Source Sans Pro', sans-serif;
            font-size: 1.1rem;
            transition: opacity 0.2s;
        }

        .nav-list a:hover {
            opacity: 0.8;
        }
    </style>
    </style>
</head>
<body>
    <div class="container">
        <nav class="nav-container">
            <ul class="nav-list">
                <li><a href="index.html">About</a></li>
                <li><a href="index.html">New</a></li>
                <li><a href="index.html">Archive</a></li>
            </ul>
        </nav>
        <article>
            <header class="article-header">
                <h1>Pushing Operator to its Limits</h1>
                <div class="tags">
                    <span>agi forecasting</span> •
                    <span>ai scaling</span> • <span>reinforcement learning</span>
                </div>
                <div class="metadata">
                    <span>2025-01-28</span> •
                    <span>status: in-progress</span> •
                    <span>importance: high</span>
                </div>
            </header>

            <section class="abstract">
                OpenAI's first version of their computer-use agent "Operator" was released to <a href="https://openai.com/index/introducing-operator/">brief fanfare</a> and obvious, glaring issues.
                <br><br>
                However, it is highly capable and its present issues seem to mostly stem from its inability to <i>see</i>. While this is of course a deciding issue for a <a href="https://openai.com/index/computer-using-agent/">computer-use agent</a>, Operator's intended usecase in this early roll-out seems to be filling out forms, and I find its ability to detect the location of text on screens is nearly flawless. It instead struggles with spatial relationships and contrasting colors. I assume OAI is using some <a href="https://deepmind.google/discover/blog/a-generalist-agent/">Gato-style</a> form of RL to generate computer-use data combined with self-supervised training on that data.
            </section>

            <div class="table-of-contents">
                <h2>Contents</h2>
                <ul>
                    <li>1. <a href="#1">Exploring Strengths</a></li>
                    <li>2. <a href="#2">Simplified Montezuma's Revenge</a></li>
                </ul>
            </div> 

            <section class="content">
                <h2 id="1">1. Exploring Strengths</h2>
              <p>Computer-using agents are of particular interest to me due to Metaculus&#39;s <a href="https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/">Date of Weakly General AI</a> market, which seems <i>resolved in spirit</i> since 2020&#39;s foreboding AI flurries, chiefly GPT-3 and Agent57, which both displayed considerable and uncanny <em>generality</em> despite their heavy constraints. 
              <p>Over the last five years, the flurries have borne into a full-on snow storm, with humans clambering to assemble cognitive benchmarks AI can&#39;t solve, and yet the market <em>still remains open</em> due to the stand-out criteria that a weakly general AI must be a <em>unified AI system</em> capable of learning Montezuma&#39;s Revenge in sub-100 hours of real-time play, along with the more traditional criteria that it must score &gt;75th percentile on the SAT, &gt;90% on WinoGrande, and pass a two-hour-long Turing test. These last three have been long since saturated, and only the most fiendishly difficult Atari game remains.</p>
              <p>My intuition is that a scaled-up Gato or frankensteined <a href="https://arxiv.org/abs/2301.04104">Dreamer-v3</a> could probably muster its way through Montezuma&#39;s Revenge without special training, since the main challenge for RL systems of the (early) 2010s wasn&#39;t the complexity of the game mechanics but that no world models existed to predict the game&#39;s sparse rewards. With systems of the 2020s now integrating RL with world modeling from unsupervised learning, the remaining issues have dwindled to pesky engineering problems, not a conceptual wall.</p>
              <p>Case in point: Language models show stunning out-of-distribution generalization in-context, and are even capable of episodic memory-style recall on their contexts. While teaching entirely new skills in-context remains a struggle, fine-tuning and reinforcement learning atop LMs now press at the barrier of <a href="https://en.wikipedia.org/wiki/OpenAI_o3">super-human (competition) coding ability</a>, and crush <a href="https://arcprize.org/blog/oai-o3-pub-breakthrough">pared-down tasks</a> attempting to test skill-acquisition.</p>
              <p>My testing of OpenAI&#39;s Operator for the last few days suggests that the Montezuma&#39;s Revenge criteria is now satisfied per its original intention, despite Operator&#39;s limitations causing it to struggle on the exact challenge. I additionally test Operator on board games, </p>
              <p>While most benchmarks aim to push models to conditions where they fail, I instead treat Operator as having idiosyncratic visual impairements and seek what conditions allow it to succeed. 
              <p>Since forecasting criteria must be precise so that they can resolve fairly for their participants, and benchmarks must be sensational between "total failure to reason" and enourmous step changes, little attention is spent on <i>how</i> systems manage to learn and accomplish tasks, not from the low-level perspective of mechanistic interpretability, but in the hands-on sense of watching how AI systems attempt tasks in-context and imagining what prosthetics might let them work around their constraints. I attempt to do that here.</p>
                <h2 id="2">2. Simplified Montezuma's Revenge</h2>
              <p>I created a simple 2d platformer game of similar &quot;abstract complexity&quot; to the first level of Montezuma&#39;s Revenge using Claude 3.5 Sonnet, modifying the game such that Operator would be able to recognize artifacts despite its "blindness". Operator impressed me not for its ability to play, but its ability to correct its mistakes, try new strategies, and apply my advice to update its strategies. In terms of the cognitive component of the challenges, exploring each room in a novel environment such as Montezuma&#39;s Revenge seems within scope of its ability, though the visual components and &quot;motor complexity&quot; of the game seems far beyond its reach.</p>
              <p>During the first successful trial run of my simplified game, Operator correctly identified the meaning of different game elements, such as hazards and a ladder (though the ladder's meaning is explained in the text instructions). It also, to my surprise, correctly figured out how to use the poorly defined "grapple" functionality, an in-game tool allowing the player to "swing" to other parts of the same level, managed to apply this to save time, and correctly used it to solve the "victory circle" puzzle at the end, though I did not explain it had to do that. It did, however, get catastrophically stuck figuring out how to actually use the ladder, seemingly owing to its inability to see its upward progress (metaphor?).</p>
              <p>Here is <a href="https://operator.chatgpt.com/v/67990f128b8481919f166c94c5e1ef3e">the video playthrough</a>, provided by OpenAI. It's slightly sped-up by their video export software. Operator is really slow! I did not interfere with the browser while Operator plays, though it does ask me for help. The video is painfully slow and contains a few minutes of Operator messing up while climbing the ladder, so if you skip most of it or watch it at 3x speed you won&#39;t miss anything. Operator allows the user to chat with the agent during task execution, and below is a reproduced transcript:</p>
              <blockquote>
              <p>User: Play this game:</p>
              <p><a href="https://koratkar.github.io/claude-game/">https://koratkar.github.io/claude-game/</a></p>
              <p>Operator: <code>Worked for 7 minutes</code> I&#39;ve attempted various strategies to move the black square to the victory circle, but it seems there&#39;s a limitation in reaching the green circle from the bottom level. The &quot;GRAPPLE&quot; button and the ladder haven&#39;t been successful. Would you like me to try something else?</p>
              <p>User: Remember, you can&#39;t grapple across levels.</p>
              <p>Operator: Got it! I&#39;ll focus on moving the black square within the same level. I&#39;ll try to align it with the victory circle using the available movement options.</p>
              <p>Operator: <code>Worked for 1 minute</code> I&#39;ve tried various approaches to move the black square to the victory circle, but it seems there&#39;s a challenge in ascending the ladder. Would you like me to try a different strategy or approach?</p>
              <p>User: You fell off the ladder.</p>
              <p>Operator: <code>Worked for 1 minute</code> I&#39;ve attempted several approaches to move the black square to the victory circle, but it seems there&#39;s a challenge in ascending the ladder. How would you like me to proceed?</p>
              <p>User: Why do you keep moving left when you go up the ladder?</p>
              <p>Operator: I&#39;m sorry for the confusion. I&#39;ll try ascending the ladder again and avoid moving left. I&#39;ll focus on moving directly to the victory circle once I reach the top level. Let me attempt that.</p>
              <p>Operator: <code>Worked for 37 seconds</code> It seems there&#39;s a challenge in ascending the ladder, as the black square isn&#39;t moving up. Would you like me to try a different approach or strategy?</p>
              <p>User: Oh, I see the issue. You can&#39;t see it going up. When you are on the ladder you <em>are</em> moving up, but movement is rather slow. If you are on the ladder, you can keep pressing up and be assured you are moving. You will receive visual indication of success once it says &quot;You are on the: TOP LEVEL&quot;.</p>
              <p>Operator: Thank you for clarifying! I&#39;ll keep pressing the &quot;UP&quot; button while on the ladder until I reach the top level. I&#39;ll look for the message indicating success. I&#39;ll start by moving the black square to the ladder and proceed from there.</p>
              <p>Operator: <code>Worked for 32 seconds</code> The game is complete! The black square reached the victory circle, and the &quot;You Won!&quot; message is displayed. Let me know if there&#39;s anything else you&#39;d like to do.</p>
              <p>User: Great job!</p>
              <p>Operator: Thank you! If you have any other tasks or need assistance, feel free to let me know.</p>
              </blockquote>
                <h2 id="3">3. In-progress sections</h2>
                  <p>Board games, social simulator games, captchas, drawing tasks, "read the document and draw your feelings"</p>
              <hr>
              <p>Thanks to <strong>Bjartur Tomas</strong> for research funding to test Operator.</p>
            </section>
        </article>
    </div>
</body>
</html>
